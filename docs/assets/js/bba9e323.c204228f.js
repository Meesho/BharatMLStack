"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6812],{2486:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"predator/v1.0.0/release-notes","title":"Release Notes","description":"Version 1.0.0","source":"@site/docs/predator/v1.0.0/release-notes.md","sourceDirName":"predator/v1.0.0","slug":"/predator/v1.0.0/release-notes","permalink":"/BharatMLStack/predator/v1.0.0/release-notes","draft":false,"unlisted":false,"editUrl":"https://github.com/Meesho/BharatMLStack/tree/main/docs/docs/predator/v1.0.0/release-notes.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Release Notes","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Key Functionalities","permalink":"/BharatMLStack/predator/v1.0.0/functionalities"}}');var s=r(4848),o=r(8453);const i={title:"Release Notes",sidebar_position:3},a="Predator - Release Notes",l={},c=[{value:"Version 1.0.0",id:"version-100",level:2},{value:"What&#39;s New",id:"whats-new",level:3}];function d(e){const n={br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"predator---release-notes",children:"Predator - Release Notes"})}),"\n",(0,s.jsx)(n.h2,{id:"version-100",children:"Version 1.0.0"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Release Date"}),": June 2025",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.strong,{children:"Status"}),": General Availability (GA)"]}),"\n",(0,s.jsxs)(n.p,{children:["First stable release of ",(0,s.jsx)(n.strong,{children:"Predator"})," \u2014 scalable model inference service built around ",(0,s.jsx)(n.strong,{children:"NVIDIA Triton Inference Server"}),", part of BharatMLStack. Serves Deep Learning and tree-based models with low latency in ",(0,s.jsx)(n.strong,{children:"Kubernetes"}),"; integrates with ",(0,s.jsx)(n.strong,{children:"OnFS"})," and ",(0,s.jsx)(n.strong,{children:"Interflow"}),"; clients use the ",(0,s.jsx)(n.strong,{children:"Helix client"})," over gRPC."]}),"\n",(0,s.jsx)(n.h3,{id:"whats-new",children:"What's New"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Triton inference engine"}),": Unified runtime for DL and tree-based models on CPU/GPU; model repository via Init Container from GCS; gRPC API via Helix client."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Multi-backend support"}),": TensorRT, PyTorch, ONNX Runtime, TensorFlow, Python, FIL, DALI, Custom."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Dynamic batching & concurrency"}),": Configurable via ",(0,s.jsx)(n.code,{children:"config.pbtxt"}),"; model versioning and ensembles."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Kubernetes deployment"}),": Helm-based; Init Container + Triton container; custom Triton images from Artifact Registry; health probes; CPU/GPU autoscaling."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Observability"}),": Prometheus metrics, Grafana; warmup requests for cold-start avoidance."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>a});var t=r(6540);const s={},o=t.createContext(s);function i(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);