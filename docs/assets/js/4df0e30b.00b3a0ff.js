"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[2379],{8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}},9680:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"numerix/v1.0.0/architecture","title":"Architecture","description":"---","source":"@site/docs/numerix/v1.0.0/architecture.md","sourceDirName":"numerix/v1.0.0","slug":"/numerix/v1.0.0/architecture","permalink":"/BharatMLStack/numerix/v1.0.0/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/Meesho/BharatMLStack/tree/main/docs/docs/numerix/v1.0.0/architecture.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"title":"Architecture","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"v1.0.0","permalink":"/BharatMLStack/numerix/v1.0.0"},"next":{"title":"Benchmarks","permalink":"/BharatMLStack/numerix/v1.0.0/benchmarks"}}');var r=i(4848),t=i(8453);const l={title:"Architecture",sidebar_position:1},o="BharatMLStack - Numerix",a={},c=[{value:"High-Level Components",id:"high-level-components",level:2},{value:"What is SIMD?",id:"what-is-simd",level:2},{value:"Why SIMD Matters for Numerix",id:"why-simd-matters-for-numerix",level:2},{value:"Why ARM, Why LLVM",id:"why-arm-why-llvm",level:2},{value:"Request Model and Flow",id:"request-model-and-flow",level:2},{value:"Why Postfix Expressions",id:"why-postfix-expressions",level:2},{value:"gRPC Interface",id:"grpc-interface",level:2},{value:"Observability",id:"observability",level:2},{value:"Environments",id:"environments",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Contributing",id:"contributing",level:2},{value:"Community &amp; Support",id:"community--support",level:2},{value:"License",id:"license",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"bharatmlstack---numerix",children:"BharatMLStack - Numerix"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsxs)(n.p,{children:["Numerix is a Rust-based compute service in ",(0,r.jsx)(n.strong,{children:"BharatMLStack"})," designed for low-latency evaluation of mathematical expressions over feature matrices. Each request carries a compute_id and a matrix of features; Numerix fetches the corresponding postfix expression, maps variables to feature columns (treated as vectors), and evaluates the expression with a stack-based SIMD-optimized runtime."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"high-level-components",children:"High-Level Components"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Tonic gRPC server (Rust)"}),": exposes ",(0,r.jsx)(n.code,{children:"Numerix/Compute"})," for low-latency requests.","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Accepts feature data as strings (for ease of use) or byte arrays (for efficient transmission)."}),"\n",(0,r.jsx)(n.li,{children:"All input data is converted internally to fp32 or fp64 vectors for evaluation."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compute Registry (etcd)"}),": stores ",(0,r.jsx)(n.code,{children:"compute_id (int) \u2192 postfix expression"})," mappings."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stack-based Evaluator"}),": Runs postfix expressions in linear time using a stack based approach over aligned vectors."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Vectorized Math Runtime"}),": No handwritten SIMD intrinsics; relies on ",(0,r.jsx)(n.strong,{children:"LLVM autovectorization"}),".","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Operations are intentionally simple and memory-aligned."}),"\n",(0,r.jsx)(n.li,{children:"Compiler emits SIMD instructions automatically."}),"\n",(0,r.jsx)(n.li,{children:"Portable across CPU architectures (ARM & AMD)."}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Metrics and Health"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Latency, RPS, and error rates via ",(0,r.jsx)(n.strong,{children:"Datadog/DogStatsD"})," UDP client."]}),"\n",(0,r.jsxs)(n.li,{children:["Minimal HTTP endpoints (",(0,r.jsx)(n.code,{children:"/health"}),", optional ",(0,r.jsx)(n.code,{children:"/metrics"}),") for diagnostics."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"what-is-simd",children:"What is SIMD?"}),"\n",(0,r.jsx)(n.p,{children:"SIMD (Single Instruction, Multiple Data) is a CPU feature that allows a single instruction to operate on multiple data points at once. In Numerix, this means that operations on feature vectors can be executed in parallel, making evaluation of mathematical expressions faster and more predictable."}),"\n",(0,r.jsx)(n.h2,{id:"why-simd-matters-for-numerix",children:"Why SIMD Matters for Numerix"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Postfix expressions operate on vectors (columns of the input matrix)."}),"\n",(0,r.jsx)(n.li,{children:"SIMD allows multiple elements of these vectors to be processed in one CPU instruction, rather than element-by-element."}),"\n",(0,r.jsx)(n.li,{children:"This results in low-latency, high-throughput computation without the need for handwritten intrinsics \u2014 the compiler handles the vectorization automatically."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"why-arm-why-llvm",children:"Why ARM, Why LLVM"}),"\n",(0,r.jsxs)(n.p,{children:["During design exploration, we tested SIMD on different architectures and found ",(0,r.jsx)(n.strong,{children:"ARM (AArch64)"})," with NEON/SVE/SVE2 provided excellent performance for our workloads."]}),"\n",(0,r.jsxs)(n.p,{children:["Instead of writing custom intrinsics, Numerix ",(0,r.jsx)(n.strong,{children:"compiles with SIMD flags"})," and lets LLVM handle vectorization:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'RUSTFLAGS="-C target-feature=+neon,+sve,+sve2" \\\ncargo build --release --target aarch64-unknown-linux-gnu\n'})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"This approach works well because operations are straightforward, data is aligned, and compiler auto-vectorization is reliable."}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"AMD/x86 builds are equally supported \u2014 enabling their SIMD extensions is just a matter of changing build flags."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"request-model-and-flow",children:"Request Model and Flow"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Client calls gRPC ",(0,r.jsx)(n.code,{children:"numerix.Numerix/Compute"})," with:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"schema"}),": ordered feature names"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"entity_scores"}),": per-entity vectors (string or bytes)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"compute_id"}),": integer identifier for the expression"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"data_type"})," (optional): e.g., ",(0,r.jsx)(n.code,{children:"fp32"})," or ",(0,r.jsx)(n.code,{children:"fp64"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Service fetches the postfix expression for ",(0,r.jsx)(n.code,{children:"compute_id"})," which was pre-fetched from ",(0,r.jsx)(n.code,{children:"etcd"}),"."]}),"\n",(0,r.jsx)(n.li,{children:"Request is validated for schema and data shape."}),"\n",(0,r.jsx)(n.li,{children:"The stack-based evaluator executes the expression in O(n) over tokens, with vectorized inner operations."}),"\n",(0,r.jsxs)(n.li,{children:["Response returns ",(0,r.jsx)(n.code,{children:"computation_score_data"})," or a structured ",(0,r.jsx)(n.code,{children:"error"}),"."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"why-postfix-expressions",children:"Why Postfix Expressions"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stored in etcd"})," as postfix (Reverse Polish) notation."]}),"\n",(0,r.jsx)(n.li,{children:"Postfix makes evaluation parser-free and linear time."}),"\n",(0,r.jsxs)(n.li,{children:["Execution uses a stack machine:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Push operands (feature vectors)."}),"\n",(0,r.jsx)(n.li,{children:"Pop, compute, and push results for each operator."}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:"Benefits: predictable runtime, compiler-friendly loops, cache efficiency."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"grpc-interface",children:"gRPC Interface"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Service:"})," ",(0,r.jsx)(n.code,{children:"numerix.Numerix"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RPC:"})," ",(0,r.jsx)(n.code,{children:"Compute(NumerixRequestProto) \u2192 NumerixResponseProto"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Request fields:"})," ",(0,r.jsx)(n.code,{children:"schema"}),", ",(0,r.jsx)(n.code,{children:"entity_scores"}),", ",(0,r.jsx)(n.code,{children:"compute_id"}),", optional ",(0,r.jsx)(n.code,{children:"data_type"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Response fields:"})," ",(0,r.jsx)(n.code,{children:"computation_score_data"})," or ",(0,r.jsx)(n.code,{children:"error"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Example (grpcurl):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'grpcurl -plaintext \\\n  -import-path ./numerix/src/protos/proto \\\n  -proto numerix.proto \\\n  -d \'{\n    "entityScoreData": {\n      "schema": ["feature1", "feature2"],\n      "entityScores": [ { "stringData": { "values": ["1.0", "2.0"] } } ],\n      "computeId": "1001",\n      "dataType": "fp32"\n    }\n  }\' \\\n  localhost:8080 numerix.Numerix/Compute\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"observability",children:"Observability"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Datadog (DogStatsD)"})," metrics publication via UDP client:","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Latency (P50/P95/P99), error rate, RPS, internal failures"}),"\n",(0,r.jsx)(n.li,{children:"Configurable sampling rate via environment variables"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Optional ",(0,r.jsx)(n.code,{children:"/metrics"})," HTTP endpoint can be enabled for local debugging."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"environments",children:"Environments"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Kubernetes (K8s), including GKE and EKS"}),"\n",(0,r.jsx)(n.li,{children:"Multi-arch builds: amd64, arm64."}),"\n",(0,r.jsx)(n.li,{children:"ARM builds ship with NEON/SVE/SVE2 enabled."}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Minimal service surface: ",(0,r.jsx)(n.strong,{children:"gRPC + etcd"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"No custom intrinsics"})," \u2014 portable across ",(0,r.jsx)(n.strong,{children:"ARM & AMD"})," via compiler flags."]}),"\n",(0,r.jsx)(n.li,{children:"Supports both string and byte input, internally converted to aligned fp32/fp64 vectors."}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Stack-based postfix evaluation"})," : linear time, cache-friendly."]}),"\n",(0,r.jsx)(n.li,{children:"Predictable, ultra-low-latency performance."}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"contributing",children:"Contributing"}),"\n",(0,r.jsxs)(n.p,{children:["We welcome contributions from the community! Please see our ",(0,r.jsx)(n.a,{href:"https://github.com/Meesho/BharatMLStack/blob/main/CONTRIBUTING.md",children:"Contributing Guide"})," for details on how to get started."]}),"\n",(0,r.jsx)(n.h2,{id:"community--support",children:"Community & Support"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\ud83d\udcac ",(0,r.jsx)(n.strong,{children:"Discord"}),": Join our ",(0,r.jsx)(n.a,{href:"https://discord.gg/XkT7XsV2AU",children:"community chat"})]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udc1b ",(0,r.jsx)(n.strong,{children:"Issues"}),": Report bugs and request features on ",(0,r.jsx)(n.a,{href:"https://github.com/Meesho/BharatMLStack/issues",children:"GitHub Issues"})]}),"\n",(0,r.jsxs)(n.li,{children:["\ud83d\udce7 ",(0,r.jsx)(n.strong,{children:"Email"}),": Contact us at ",(0,r.jsx)(n.a,{href:"mailto:ml-oss@meesho.com",children:"ml-oss@meesho.com"})]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"license",children:"License"}),"\n",(0,r.jsxs)(n.p,{children:["BharatMLStack is open-source software licensed under the ",(0,r.jsx)(n.a,{href:"https://github.com/Meesho/BharatMLStack/blob/main/LICENSE.md",children:"BharatMLStack Business Source License 1.1"}),"."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)("div",{align:"center",children:(0,r.jsx)("strong",{children:"Built with \u2764\ufe0f for the ML community from Meesho"})}),"\n",(0,r.jsx)("div",{align:"center",children:(0,r.jsx)("strong",{children:"If you find this useful, \u2b50\ufe0f the repo \u2014 your support means the world to us!"})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);