"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7813],{1566:e=>{e.exports=JSON.parse('{"categoryGeneratedIndex":{"title":"Predator","description":"Predator is a scalable, high-performance model inference service built as a wrapper around NVIDIA Triton Inference Server, designed to serve ML models with low latency in Kubernetes, with OnFS and Interflow integration.","slug":"/category/predator","permalink":"/BharatMLStack/category/predator","sidebar":"tutorialSidebar","navigation":{"previous":{"title":"Release Notes","permalink":"/BharatMLStack/numerix/v1.0.0/release-notes"},"next":{"title":"v1.0.0","permalink":"/BharatMLStack/predator/v1.0.0"}}}}')}}]);