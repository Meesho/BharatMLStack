version: '3.8'

# BharatML Stack Application Versions
# To test different versions, set environment variables:
#   ONFS_VERSION=v1.2.3 HORIZON_VERSION=v2.1.0 NUMERIX_VERSION=v1.0.0 TRUFFLEBOX_VERSION=v1.0.5 INFERFLOW_VERSION=v1.0.0 docker-compose up
# Or modify the default values below:
#   ONFS_VERSION: latest
#   HORIZON_VERSION: latest
#   NUMERIX_VERSION: latest
#   TRUFFLEBOX_VERSION: latest
#   INFERFLOW_VERSION: latest

services:
  # Infrastructure Services
  scylla:
    image: scylladb/scylla:6.2
    container_name: scylla
    ports:
      - "9042:9042"
    volumes:
      - scylla-data:/var/lib/scylla
    command: --smp 1 --memory 512M
    networks:
      onfs-network:
        ipv4_address: 172.18.0.2
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -e 'SELECT now() FROM system.local'"]
      interval: 30s
      timeout: 10s
      retries: 5

  mysql:
    image: mysql:8
    container_name: mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: testdb
      MYSQL_USER: user
      MYSQL_PASSWORD: password
    ports:
      - "3306:3306"
    volumes:
      - mysql-data:/var/lib/mysql
    networks:
      onfs-network:
        ipv4_address: 172.18.0.4
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    image: redis:7
    container_name: redis
    ports:
      - "6379:6379"
    command: ["redis-server", "--requirepass", ""]
    networks:
      onfs-network:
        ipv4_address: 172.18.0.5
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.16.0
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-data:/qdrant/storage
    networks:
      onfs-network:
        ipv4_address: 172.18.0.3
    healthcheck:
      # Qdrant image has no curl; use bash TCP check (port 6333 open = ready)
      test: ["CMD-SHELL", "bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
   
  kafka:
    image: apache/kafka:latest
    hostname: broker
    container_name: broker
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_CREATE_TOPICS: online-feature-store.feature_ingestion:1:1
    networks:
      onfs-network:
        ipv4_address: 172.18.0.6
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s  

  kafka-init:
    image: apache/kafka:latest
    container_name: kafka-init
    networks:
      onfs-network:
        ipv4_address: 172.18.0.7
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      # Wait for Kafka to be ready
      echo 'Waiting for Kafka to be ready...'
      sleep 10
      
      # Create ONFS topic
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic online-feature-store.feature_ingestion --partitions 1 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic inferflow_inference_logs --partitions 1 --replication-factor 1
      
      # Create Skye topics
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic skye.model-state --partitions 1 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic skye.embedding --partitions 1 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic skye.embedding-sequence --partitions 1 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic skye.realtime --partitions 1 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server broker:29092 --create --if-not-exists --topic skye.realtime-delta --partitions 1 --replication-factor 1
      
      echo 'Topics created successfully!'
      "
    restart: "no"

  etcd:
    image: quay.io/coreos/etcd:v3.5.12
    container_name: etcd
    environment:
      - ALLOW_NONE_AUTHENTICATION=yes
      - ETCD_LISTEN_CLIENT_URLS=http://0.0.0.0:2379
      - ETCD_ADVERTISE_CLIENT_URLS=http://0.0.0.0:2379
    ports:
      - "2378:2379"
    networks:
      onfs-network:
        ipv4_address: 172.18.0.8
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Database Initialization Service
  db-init:
    build:
      context: ./db-init
      dockerfile: Dockerfile
    container_name: db-init
    environment:
      - INIT_DUMMY_DATA=${INIT_DUMMY_DATA:-false}
    networks:
      onfs-network:
        ipv4_address: 172.18.0.9
    depends_on:
      scylla:
        condition: service_healthy
      mysql:
        condition: service_healthy
      redis:
        condition: service_healthy
      etcd:
        condition: service_healthy

    restart: "no"

  # BharatML Stack Services
  onfs-api-server:
    image: ghcr.io/meesho/onfs-api-server:${ONFS_VERSION:-latest}
    container_name: onfs-api-server
    ports:
      - "8089:8089"
    environment:
      - APP_ENV=local
      - APP_LOG_LEVEL=DEBUG
      - APP_METRIC_SAMPLING_RATE=1
      - APP_NAME=onfs
      - APP_PORT=8089
      - AUTH_TOKEN=test
      - POD_IP=onfs-api-server
      - NODE_IP=onfs-api-server
      - STORAGE_REDIS_STANDALONE_2_ADDR=redis:6379
      - STORAGE_REDIS_STANDALONE_2_DB=0
      - STORAGE_REDIS_STANDALONE_2_DISABLE_IDENTITY=true
      - STORAGE_REDIS_STANDALONE_2_MAX_IDLE_CONN=32
      - STORAGE_REDIS_STANDALONE_2_MIN_IDLE_CONN=20
      - STORAGE_REDIS_STANDALONE_2_MAX_ACTIVE_CONN=32
      - STORAGE_REDIS_STANDALONE_2_MAX_RETRY=-1
      - STORAGE_REDIS_STANDALONE_2_POOL_FIFO=false
      - STORAGE_REDIS_STANDALONE_2_READ_TIMEOUT_IN_MS=300
      - STORAGE_REDIS_STANDALONE_2_WRITE_TIMEOUT_IN_MS=300
      - STORAGE_REDIS_STANDALONE_2_POOL_TIMEOUT_IN_MS=300
      - STORAGE_REDIS_STANDALONE_2_POOL_SIZE=32
      - STORAGE_REDIS_STANDALONE_2_CONN_MAX_IDLE_TIMEOUT_IN_MINUTES=15
      - STORAGE_REDIS_STANDALONE_2_CONN_MAX_AGE_IN_MINUTES=30
      - STORAGE_REDIS_STANDALONE_ACTIVE_CONFIG_IDS=2
      - DISTRIBUTED_CACHE_CONF_IDS=2
      - ETCD_SERVER=http://etcd:2379
      - ETCD_WATCHER_ENABLED=true
      - IN_MEM_CACHE_3_ENABLED=true
      - IN_MEM_CACHE_3_NAME=onfs
      - IN_MEM_CACHE_3_SIZE_IN_BYTES=100000
      - IN_MEM_CACHE_ACTIVE_CONFIG_IDS=3
      - STORAGE_SCYLLA_1_CONTACT_POINTS=scylla
      - STORAGE_SCYLLA_1_KEYSPACE=onfs
      - STORAGE_SCYLLA_1_PORT=9042
      - STORAGE_SCYLLA_1_NUM_CONNS=1
      - STORAGE_SCYLLA_1_TIMEOUT_IN_MS=300000
      - STORAGE_SCYLLA_1_USERNAME=
      - STORAGE_SCYLLA_1_PASSWORD=
      - STORAGE_SCYLLA_1_MAJOR_VERSION=5
      - STORAGE_SCYLLA_1_SCYLLA_VERSION=5
      - STORAGE_SCYLLA_ACTIVE_CONFIG_IDS=1
      - P2P_CACHE_5_ENABLED=true
      - P2P_CACHE_5_CLUSTER_NAME=onfs-cluster
      - P2P_CACHE_5_NAME=p2p-onfs
      - P2P_CACHE_5_OWN_PARTITION_SIZE_IN_BYTES=100000
      - P2P_CACHE_5_GLOBAL_SIZE_IN_BYTES=1000
      - P2P_CACHE_5_GLOBAL_CACHE_TTL_IN_SECONDS=3600
      - P2P_CACHE_5_NUM_CLIENTS=2
      - P2P_CACHE_5_SERVER_PORT=8088
      - P2P_CACHE_ACTIVE_CONFIG_IDS=5
      - ENABLE_HTTP_API=true
    networks:
      onfs-network:
        ipv4_address: 172.18.0.10
    depends_on:
      db-init:
        condition: service_completed_successfully
    restart: unless-stopped

  # External health check for onfs-api-server (since it's a distroless container)
  onfs-healthcheck:
    image: alpine:latest
    container_name: onfs-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.11
    depends_on:
      - onfs-api-server
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://onfs-api-server:8089/health/self"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    restart: "no"

  onfs-consumer:
    image: ghcr.io/meesho/onfs-consumer:${ONFS_CONSUMER_VERSION:-latest}
    container_name: onfs-consumer
    ports:
      - "8090:8090"
      - "8080:8080"
    environment:
      - APP_ENV=local
      - APP_LOG_LEVEL=DEBUG
      - APP_METRIC_SAMPLING_RATE=1
      - APP_NAME=onfs
      - APP_PORT=8090
      # Kafka Consumer Configuration
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_AUTO_OFFSET_RESET=earliest
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_BATCH_SIZE=100
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_BASIC_AUTH_CREDENTIAL_SOURCE=USER_INFO
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_SASL_MECHANISM=PLAIN
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_SASL_PASSWORD=
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_SASL_USERNAME=
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_SECURITY_PROTOCOL=SASL_PLAINTEXT
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_CLIENT_ID=onfs-consumer
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_ENABLE_AUTO_COMMIT=true
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_GROUP_ID=onfs-consumer-group
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_LISTENER_CONCURRENCY=2
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_MAX_WORKERS=50
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_POLL_TIMEOUT=1000
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_SECURITY_PROTOCOL=PLAINTEXT
      - KAFKA_CONSUMERS_FEATURE_CONSUMER_TOPIC=online-feature-store.feature_ingestion
      # Storage Configuration (Redis)
      - STORAGE_REDIS_STANDALONE_2_ADDR=redis:6379
      - STORAGE_REDIS_STANDALONE_2_DB=0
      - STORAGE_REDIS_STANDALONE_2_DISABLE_IDENTITY=true
      - STORAGE_REDIS_STANDALONE_2_MAX_IDLE_CONN=32
      - STORAGE_REDIS_STANDALONE_2_MIN_IDLE_CONN=20
      - STORAGE_REDIS_STANDALONE_2_MAX_ACTIVE_CONN=32
      - STORAGE_REDIS_STANDALONE_2_MAX_RETRY=-1
      - STORAGE_REDIS_STANDALONE_2_POOL_FIFO=false
      - STORAGE_REDIS_STANDALONE_2_READ_TIMEOUT_IN_MS=3000
      - STORAGE_REDIS_STANDALONE_2_WRITE_TIMEOUT_IN_MS=3000
      - STORAGE_REDIS_STANDALONE_2_POOL_TIMEOUT_IN_MS=3000
      - STORAGE_REDIS_STANDALONE_2_POOL_SIZE=32
      - STORAGE_REDIS_STANDALONE_2_CONN_MAX_IDLE_TIMEOUT_IN_MINUTES=15
      - STORAGE_REDIS_STANDALONE_2_CONN_MAX_AGE_IN_MINUTES=30
      - STORAGE_REDIS_STANDALONE_ACTIVE_CONFIG_IDS=2
      # Storage Configuration (Scylla)
      - STORAGE_SCYLLA_1_CONTACT_POINTS=scylla
      - STORAGE_SCYLLA_1_KEYSPACE=onfs
      - STORAGE_SCYLLA_1_PORT=9042
      - STORAGE_SCYLLA_1_NUM_CONNS=1
      - STORAGE_SCYLLA_1_TIMEOUT_IN_MS=300000
      - STORAGE_SCYLLA_1_USERNAME=
      - STORAGE_SCYLLA_1_PASSWORD=
      - STORAGE_SCYLLA_1_MAJOR_VERSION=5
      - STORAGE_SCYLLA_1_SCYLLA_VERSION=5
      - STORAGE_SCYLLA_ACTIVE_CONFIG_IDS=1
      # Etcd Configuration
      - ETCD_SERVER=http://etcd:2379
      - ETCD_WATCHER_ENABLED=true
    networks:
      onfs-network:
        ipv4_address: 172.18.0.12
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      db-init:
        condition: service_completed_successfully
    restart: unless-stopped

  onfs-consumer-healthcheck:
    image: alpine:latest
    container_name: onfs-consumer-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.13
    depends_on:
      - onfs-consumer
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://onfs-consumer:8090/health/self"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 90s
    restart: "no"
    
  horizon:
    image: ghcr.io/meesho/horizon:${HORIZON_VERSION:-latest}
    container_name: horizon
    ports:
      - "8082:8082"
    environment:
      - APP_NAME=horizon
      - APP_ENV=PROD
      - APP_PORT=8082
      - APP_LOG_LEVEL=DEBUG
      - APP_METRIC_SAMPLING_RATE=1
      - APP_GC_PERCENTAGE=1
      - MYSQL_MASTER_MAX_POOL_SIZE=5
      - MYSQL_MASTER_MIN_POOL_SIZE=2
      - MYSQL_MASTER_PASSWORD=root
      - MYSQL_MASTER_HOST=mysql
      - MYSQL_MASTER_PORT=3306
      - MYSQL_DB_NAME=testdb
      - MYSQL_MASTER_USERNAME=root
      - MYSQL_SLAVE_MAX_POOL_SIZE=5
      - MYSQL_SLAVE_MIN_POOL_SIZE=2
      - MYSQL_SLAVE_PASSWORD=root
      - MYSQL_SLAVE_HOST=mysql
      - MYSQL_SLAVE_PORT=3306
      - MYSQL_SLAVE_PORT=3306
      - MYSQL_SLAVE_USERNAME=root
      - MYSQL_ACTIVE_CONFIG_IDS=2
      - ETCD_WATCHER_ENABLED=true
      - ETCD_SERVER=etcd:2379
      - ONLINE_FEATURE_STORE_APP_NAME=onfs
      - REDIS_FAILOVER_ACTIVE_CONFIG_IDS=4
      - SCYLLA_1_CONTACT_POINTS=scylla
      - SCYLLA_1_KEYSPACE=onfs
      - SCYLLA_1_NUM_CONNS=1
      - SCYLLA_1_PORT=9042
      - SCYLLA_1_TIMEOUT_IN_MS=300000
      - SCYLLA_1_PASSWORD=
      - SCYLLA_1_USERNAME=
      - SCYLLA_ACTIVE_CONFIG_IDS=1
      - DISTRIBUTED_CACHE_ACTIVE_CONFIG_IDS=2
      - IN_MEMORY_CACHE_ACTIVE_CONFIG_IDS=3
      - CORS_ORIGINS=http://localhost:3000,http://localhost:8080
      - HORIZON_APP_NAME=horizon
      - NUMERIX_APP_NAME=numerix
      - INFERFLOW_APP_NAME=inferflow
      - IS_DUMMY_MODEL_ENABLED=true
      - ARGOCD_API=http://host.docker.internal:8087
      - ARGOCD_TOKEN=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9....
      - ARGOCD_NAMESPACE=argocd
      - ARGOCD_DESTINATION_NAME=in-cluster
      - ARGOCD_PROJECT=default
      - ARGOCD_HELMCHART_PATH=1.0.0
      - ARGOCD_SYNC_POLICY_OPTIONS=CreateNamespace=true
      - ARGOCD_INSECURE=true
      - LOCAL_MODEL_PATH=/tmp/models
      - SUPPORTED_ENVIRONMENTS=prd,stg,int
      - WORKING_ENV=prd
      - SERVICE_CONFIG_SOURCE=local
      - SERVICE_CONFIG_REPO=BharatMLStack-configs
      - SERVICE_CONFIG_PATH=/app/configs
      - REPOSITORY_NAME=onboarding-test
      - BRANCH_NAME=main
      - GITHUB_APP_ID=2546855
      - GITHUB_INSTALLATION_ID=101432634
      - GITHUB_PRIVATE_KEY=/app/configs/github.pem
      - GITHUB_OWNER=Adit2607
      - GITHUB_COMMIT_AUTHOR=horizon-bot
      - GITHUB_COMMIT_EMAIL=aditya.garg@meesho.com
      - GCP_PROJECT_ID=meesho-datascience-dev
      - GCS_ENABLED=true
      - GCS_MODEL_BUCKET=gcs-dsci-model-repository-int
      - GCS_MODEL_BASE_PATH=dummy
      # Application Default Credentials (ADC) configuration
      # Mounts host's gcloud credentials for ADC authentication
      # Container runs as non-root user (nonroot), so mount to /home/nonroot/.config/gcloud
      - CLOUDSDK_CONFIG=/home/nonroot/.config/gcloud
      - TEST_DEPLOYABLE_ID=3020
      - TEST_GPU_DEPLOYABLE_ID=3020
      - SKYE_APP_NAME=skye
      - SKYE_SCYLLA_ACTIVE_CONFIG_IDS=2
      - SKYE_HOST=scylla
      - SKYE_PORT=9042
      - SKYE_AUTH_TOKEN=
      - SKYE_DEADLINE_EXCEED_MS=2000
      - AIRFLOW_BASE_URL=http://airflow:8080
      - AIRFLOW_USERNAME=airflow
      - AIRFLOW_PASSWORD=airflow
      # Prism configuration
      - PRISM_BASE_URL=http://prism:8080
      - PRISM_APP_USER_ID=airflow
      - INITIAL_INGESTION_PRISM_JOB_ID=679
      - INITIAL_INGESTION_PRISM_STEP_ID=1706
      - INITIAL_INGESTION_AIRFLOW_DAG_ID=JOB_V2_skye_initial_ingestion
      - VARIANT_SCALEUP_CRON_EXPRESSION=0 */1 * * * *
      - VARIANT_SCALEUP_PRISM_JOB_ID=680
      - VARIANT_SCALEUP_PRISM_STEP_ID=2420
      - VARIANT_SCALEUP_AIRFLOW_DAG_ID=JOB_V2_variant_processor_skye
      - VARIANT_ONBOARDING_CRON_EXPRESSION=0 */1 * * * *
      # Variants list
      - VARIANTS_LIST=ads_gold,ads_mall,ads_new_catalog,ads,ct_gst,ct_high_asp,ct_non_gst,organic_gold,organic,organic_gst,organic_high_asp,organic_mall,organic_melp,organic_non_gst,widget_ads,organic_gst_pd
      # MQ configuration
      - MQ_ID_TOPICS_MAPPING=2450:skye.embeddings-1
      # Horizon to Skye ScyllaDB configuration
      - HORIZON_TO_SKYE_SCYLLA_CONF_ID_MAP=2:1
      - SCYLLA_2_CONTACT_POINTS=scylla
      - SCYLLA_2_PORT=9042
      - SCYLLA_2_KEYSPACE=skye
      - SCYLLA_2_USERNAME=
      - SCYLLA_2_PASSWORD=
      # OSS: use skye-trigger instead of Airflow for initial ingestion / variant processor
      - USE_SKYE_TRIGGER_INSTEAD_OF_AIRFLOW=true
      - SKYE_TRIGGER_URL=http://skye-trigger:8080
    volumes:
      - ./configs:/app/configs:ro
      # Mount gcloud credentials for Application Default Credentials (ADC)
      # Run 'gcloud auth application-default login' on host first
      # Container runs as non-root user, so mount to /home/nonroot/.config/gcloud
      - ~/.config/gcloud:/home/nonroot/.config/gcloud:ro
    networks:
      onfs-network:
        ipv4_address: 172.18.0.14
    depends_on:
      db-init:
        condition: service_completed_successfully
    restart: unless-stopped

  horizon-healthcheck:
    image: alpine:latest
    container_name: horizon-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.15
    depends_on:
      - horizon
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://horizon:8082/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  numerix:
    image: ghcr.io/meesho/numerix:${NUMERIX_VERSION:-latest}
    container_name: numerix
    ports:
      - "8083:8083"
    environment:
      - APPLICATION_PORT=8083
      - APP_ENV=prd
      - APP_LOG_LEVEL=ERROR
      - APP_NAME=numerix
      - CHANNEL_BUFFER_SIZE=10000
      - ETCD_SERVERS=http://etcd:2379
      - METRIC_SAMPLING_RATE=1
      - TELEGRAF_UDP_HOST=host.docker.internal
      - TELEGRAF_UDP_PORT=8125
    networks:
      onfs-network:
        ipv4_address: 172.18.0.16
    depends_on:
      db-init:
        condition: service_completed_successfully
    restart: unless-stopped

  numerix-healthcheck:
    image: alpine:latest
    container_name: numerix-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.17
    depends_on:
      - numerix
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://numerix:8083/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  inferflow:
    image: ghcr.io/meesho/inferflow:${INFERFLOW_VERSION:-latest}
    container_name: inferflow
    ports:
      - "8085:8085"
    extra_hosts:
      # Allow inferflow to reach K8s services via host port-forward
      # Use: kubectl -n prd-predator port-forward svc/prd-predator 8090:80
      - "predator.prd.meesho.int:host-gateway"
      # Add more services as needed:
      # - "another-service.prd.meesho.int:host-gateway"
    environment:
      - APP_GC_PERCENTAGE=1
      - ETCD_SERVER=http://etcd:2379
      - ETCD_WATCHER_ENABLED=true
      - IN_MEMORY_CACHE_SIZE_IN_BYTES=6000000000
      - NUMERIX_CLIENT_V1_AUTHTOKEN=numerix
      - NUMERIX_CLIENT_V1_BATCHSIZE=100
      - NUMERIX_CLIENT_V1_DEADLINE_MS=5000
      - NUMERIX_CLIENT_V1_HOST=numerix
      - NUMERIX_CLIENT_V1_PLAINTEXT=true
      - NUMERIX_CLIENT_V1_PORT=8083
      - APP_ENV=prod
      - APP_LOG_LEVEL=INFO
      - APP_NAME=inferflow
      - APP_PORT=8085
      - DAG_TOPOLOGY_CACHE_SIZE=500
      - DAG_TOPOLOGY_CACHE_TTL_SEC=300
      - EXTERNAL_SERVICE_ONFS_FS_BATCH_SIZE=50
      - EXTERNAL_SERVICE_ONFS_FS_CALLER_ID=inferflow
      - EXTERNAL_SERVICE_ONFS_FS_CALLER_TOKEN=inferflow
      - EXTERNAL_SERVICE_ONFS_FS_GRPC_PLAIN_TEXT=true
      - EXTERNAL_SERVICE_ONFS_FS_HOST=onfs-api-server
      - EXTERNAL_SERVICE_ONFS_FS_PORT=8089
      - EXTERNAL_SERVICE_ONFS_FS_DEAD_LINE=200
      # Predator config: Port must match K8s service port 80 (not targetPort 8001)
      # Since we forward localhost:8090 -> K8s service:80 -> pod:8001
      # The model endpoint in etcd must be configured as: predator.prd.meesho.int:8090
      - EXTERNAL_SERVICE_PREDATOR_PORT=8090
      - EXTERNAL_SERVICE_PREDATOR_GRPC_PLAIN_TEXT=true
      - EXTERNAL_SERVICE_PREDATOR_CALLER_ID=inferflow
      - EXTERNAL_SERVICE_PREDATOR_CALLER_TOKEN=inferflow
      - EXTERNAL_SERVICE_PREDATOR_DEADLINE=200
      - METRIC_SAMPLING_RATE=1
      - KAFKA_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_LOGGING_TOPIC=inferflow_inference_logs
    networks:
      onfs-network:
        ipv4_address: 172.18.0.18
    depends_on:
      db-init:
        condition: service_completed_successfully
    restart: unless-stopped

  inferflow-healthcheck:
    image: alpine:latest
    container_name: inferflow-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.19
    depends_on:
      - inferflow
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://inferflow:8085/health/self"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  skye-admin:
    image: ghcr.io/meesho/skye-admin:${SKYE_VERSION:-latest}
    container_name: skye-admin
    ports:
      - "8092:8092"
    environment:
      # Application
      - APP_NAME=skye
      - APP_ENV=local
      - APP_LOG_LEVEL=INFO
      - APP_METRIC_SAMPLING_RATE=100
      - PORT=8092
      # Etcd
      - ETCD_SERVER=etcd:2379
      - ETCD_WATCHER_ENABLED=true
      # Model state Kafka producer (ID=1)
      - MODEL_STATE_PRODUCER=1
      - KAFKA_PRODUCER_1_TOPICS=skye.model-state
      - KAFKA_PRODUCER_1_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_PRODUCER_1_CLIENT_ID=skye-admin-producer
      # Model state Kafka consumer (ID=1)
      - MODEL_STATE_CONSUMER=1
      - KAFKA_1_TOPICS=skye.model-state
      - KAFKA_1_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_1_BASIC_AUTH_CREDENTIAL_SOURCE=NONE
      - KAFKA_1_GROUP_ID=skye-admin-model-state
      - KAFKA_1_AUTO_OFFSET_RESET=earliest
      - KAFKA_1_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_1_ENABLE_AUTO_COMMIT=false
      - KAFKA_1_LISTENER_CONCURRENCY=1
      - KAFKA_1_CLIENT_ID=skye-admin-consumer
      - KAFKA_1_BATCH_SIZE=10
      - KAFKA_1_POLL_TIMEOUT=1000
    networks:
      onfs-network:
        ipv4_address: 172.18.0.20
    depends_on:
      - etcd
      - kafka
      - qdrant
    restart: unless-stopped

  skye-admin-healthcheck:
    image: alpine:latest
    container_name: skye-admin-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.21
    depends_on:
      - skye-admin
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://skye-admin:8092/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  # OSS replacement for Airflow: trigger embedding jobs by calling skye-admin and producing random data to Kafka
  skye-trigger:
    build:
      context: ./skye-trigger
      dockerfile: Dockerfile
    container_name: skye-trigger
    ports:
      - "8095:8080"
    environment:
      - PORT=8080
      - SKYE_ADMIN_URL=http://skye-admin:8092
      - KAFKA_BOOTSTRAP_SERVERS=broker:29092
      - SKYE_ENVIRONMENT=local
      - SKYE_TRIGGER_NUM_POINTS=10000
      - SKYE_EMBEDDING_DIM=128
      - LOG_LEVEL=${SKYE_TRIGGER_LOG_LEVEL:-INFO}
    networks:
      onfs-network:
        ipv4_address: 172.18.0.22
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      skye-admin:
        condition: service_started
    restart: unless-stopped

  skye-consumers:
    image: ghcr.io/meesho/skye-consumers:${SKYE_VERSION:-latest}
    container_name: skye-consumers
    ports:
      - "8093:8093"
    environment:
      # Application
      - APP_NAME=skye
      - APP_ENV=local
      - APP_LOG_LEVEL=INFO
      - APP_METRIC_SAMPLING_RATE=100
      - PORT=8093
      # Etcd
      - ETCD_SERVER=etcd:2379
      - ETCD_WATCHER_ENABLED=true
      # Embedding consumer (ID=2)
      - EMBEDDING_CONSUMER_KAFKA_IDS=2
      - KAFKA_2_TOPICS=skye.embedding
      - KAFKA_2_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_2_BASIC_AUTH_CREDENTIAL_SOURCE=NONE
      - KAFKA_2_GROUP_ID=skye-embedding-consumer
      - KAFKA_2_AUTO_OFFSET_RESET=earliest
      - KAFKA_2_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_2_ENABLE_AUTO_COMMIT=false
      - KAFKA_2_LISTENER_CONCURRENCY=1
      - KAFKA_2_CLIENT_ID=skye-embedding-consumer
      - KAFKA_2_BATCH_SIZE=10
      - KAFKA_2_POLL_TIMEOUT=1000
      # Embedding sequence consumer (ID=3)
      - EMBEDDING_CONSUMER_SEQUENCE_KAFKA_IDS=3
      - KAFKA_3_TOPICS=skye.embedding-sequence
      - KAFKA_3_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_3_BASIC_AUTH_CREDENTIAL_SOURCE=NONE
      - KAFKA_3_GROUP_ID=skye-embedding-seq-consumer
      - KAFKA_3_AUTO_OFFSET_RESET=earliest
      - KAFKA_3_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_3_ENABLE_AUTO_COMMIT=false
      - KAFKA_3_LISTENER_CONCURRENCY=1
      - KAFKA_3_CLIENT_ID=skye-embedding-seq-consumer
      - KAFKA_3_BATCH_SIZE=10
      - KAFKA_3_POLL_TIMEOUT=1000
      # Realtime consumer (ID=4)
      - REALTIME_CONSUMER_KAFKA_IDS=4
      - KAFKA_4_TOPICS=skye.realtime
      - KAFKA_4_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_4_BASIC_AUTH_CREDENTIAL_SOURCE=NONE
      - KAFKA_4_GROUP_ID=skye-realtime-consumer
      - KAFKA_4_AUTO_OFFSET_RESET=earliest
      - KAFKA_4_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_4_ENABLE_AUTO_COMMIT=false
      - KAFKA_4_LISTENER_CONCURRENCY=1
      - KAFKA_4_CLIENT_ID=skye-realtime-consumer
      - KAFKA_4_BATCH_SIZE=10
      - KAFKA_4_POLL_TIMEOUT=1000
      # Realtime producer (ID=5)
      - REALTIME_PRODUCER_KAFKA_ID=5
      - KAFKA_PRODUCER_5_TOPICS=skye.realtime
      - KAFKA_PRODUCER_5_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_PRODUCER_5_CLIENT_ID=skye-realtime-producer
      # Realtime delta producer (ID=6)
      - REALTIME_DELTA_PRODUCER_KAFKA_ID=6
      - KAFKA_PRODUCER_6_TOPICS=skye.realtime-delta
      - KAFKA_PRODUCER_6_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_PRODUCER_6_CLIENT_ID=skye-realtime-delta-producer
      # Realtime delta consumer (ID=7)
      - REALTIME_DELTA_CONSUMER_KAFKA_ID=7
      - KAFKA_7_TOPICS=skye.realtime-delta
      - KAFKA_7_BOOTSTRAP_SERVERS=broker:29092
      - KAFKA_7_BASIC_AUTH_CREDENTIAL_SOURCE=NONE
      - KAFKA_7_GROUP_ID=skye-realtime-delta-consumer
      - KAFKA_7_AUTO_OFFSET_RESET=earliest
      - KAFKA_7_AUTO_COMMIT_INTERVAL_MS=5000
      - KAFKA_7_ENABLE_AUTO_COMMIT=false
      - KAFKA_7_LISTENER_CONCURRENCY=1
      - KAFKA_7_CLIENT_ID=skye-realtime-delta-consumer
      - KAFKA_7_BATCH_SIZE=10
      - KAFKA_7_POLL_TIMEOUT=1000
    networks:
      onfs-network:
        ipv4_address: 172.18.0.23
    depends_on:
      etcd:
        condition: service_healthy
      qdrant:
        condition: service_healthy
      kafka:
        condition: service_healthy
      kafka-init:
        condition: service_completed_successfully
    restart: unless-stopped

  skye-consumers-healthcheck:
    image: alpine:latest
    container_name: skye-consumers-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.24
    depends_on:
      - skye-consumers
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://skye-consumers:8093/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  skye-serving:
    image: ghcr.io/meesho/skye-serving:${SKYE_VERSION:-latest}
    container_name: skye-serving
    ports:
      - "8094:8094"
    environment:
      # Application
      - APP_NAME=skye
      - APP_ENV=local
      - APP_LOG_LEVEL=INFO
      - APP_PORT=8094
      - APP_METRIC_SAMPLING_RATE=100
      # In-memory cache (10 MB)
      - IN_MEMORY_CACHE_SIZE_IN_BYTES=10485760
      # Etcd
      - ETCD_SERVER=etcd:2379
      - ETCD_WATCHER_ENABLED=true
      # Redis
      - REDIS_ADDR=redis:6379
      - REDIS_DB=0
      # Profiling (disabled for quick-start)
      - PROFILING_ENABLED=false
      # Storage (no external ScyllaDB in quick-start)
      - STORAGE_AGGREGATOR_DB_COUNT=0
      - STORAGE_EMBEDDING_STORE_COUNT=0
      - AUTH_TOKENS=test
    networks:
      onfs-network:
        ipv4_address: 172.18.0.25
    depends_on:
      - etcd
      - redis
      - qdrant
    restart: unless-stopped

  skye-serving-healthcheck:
    image: alpine:latest
    container_name: skye-serving-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.26
    depends_on:
      - skye-serving
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://skye-serving:8094/health/self"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    restart: "no"

  trufflebox-ui:
    image: ghcr.io/meesho/trufflebox-ui:${TRUFFLEBOX_VERSION:-latest}
    container_name: trufflebox
    ports:
      - "3000:80"
    environment:
      - REACT_APP_ENVIRONMENT=production
      - REACT_APP_HORIZON_BASE_URL=http://localhost:8082
      - REACT_APP_ONLINE_FEATURE_STORE_ENABLED=true
      - REACT_APP_INFERFLOW_ENABLED=true
      - REACT_APP_NUMERIX_ENABLED=true
      - REACT_APP_PREDATOR_ENABLED=true
      - REACT_APP_EMBEDDING_PLATFORM_ENABLED=false
    networks:
      onfs-network:
        ipv4_address: 172.18.0.27
    depends_on:
      horizon-healthcheck:
        condition: service_healthy
    restart: unless-stopped

  trufflebox-healthcheck:
    image: alpine:latest
    container_name: trufflebox-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.28
    depends_on:
      - trufflebox-ui
    command: sh -c "apk add --no-cache curl && sleep infinity"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://trufflebox:3000/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  predator:
    build:
      context: ..
      dockerfile: predator-dummy/Dockerfile
    container_name: predator
    ports:
      - "8001:8001"
    environment:
      - PORT=8001
    networks:
      onfs-network:
        ipv4_address: 172.18.0.29
    healthcheck:
      test: ["CMD-SHELL", "nc -z localhost 8001 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    restart: unless-stopped

  predator-healthcheck:
    image: alpine:latest
    container_name: predator-healthcheck
    networks:
      onfs-network:
        ipv4_address: 172.18.0.30
    depends_on:
      - predator
    command: sh -c "apk add --no-cache curl netcat-openbsd && sleep infinity"
    healthcheck:
      test: ["CMD", "nc", "-z", "predator", "8001"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    restart: "no"

  # Optional: Management Tools
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8084:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=broker:29092
      - DYNAMIC_CONFIG_ENABLED=true
    networks:
      onfs-network:
        ipv4_address: 172.18.0.31
    depends_on:
      - kafka
    restart: unless-stopped

  etcd-workbench:
    image: tzfun/etcd-workbench:latest
    container_name: etcd-workbench
    ports:
      - "8081:8002"
    networks:
      onfs-network:
        ipv4_address: 172.18.0.32
    depends_on:
      - etcd

volumes:
  scylla-data:
    driver: local
  mysql-data:
    driver: local
  qdrant-data:
    driver: local

networks:
  onfs-network:
    name: onfs-network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.18.0.0/16
