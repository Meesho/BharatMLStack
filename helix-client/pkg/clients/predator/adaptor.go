package predator

import (
	"encoding/binary"
	"fmt"
	"math"
	"strconv"

	"strings"

	triton "github.com/Meesho/BharatMLStack/helix-client/pkg/clients/predator/client/grpc"
	"github.com/Meesho/go-core/datatypeconverter/types"
	"github.com/Meesho/go-core/utils"
	"github.com/rs/zerolog/log"
)

const (
	datatypeBytes = "BYTES"
)

type IAdapter interface {
	MapPredatorRequestToProto(predatorRequest *PredatorRequest, predatorDataType PredatorDataType, batches []BatchInfo) []*triton.ModelInferRequest
	MapProtoToPredatorResponse(tritonResponse *triton.ModelInferResponse, requestedOutputs []Output, predatorDataType PredatorDataType) *PredatorResponse
}

type Adapter struct {
	IAdapter
}

// PredatorDataType represents the type of data in a predator input
type PredatorDataType int

const (
	PredatorDataTypeNone PredatorDataType = iota
	PredatorDataTypeBytes
	PredatorDataTypeString
)

// getInputDataForProcessing returns the byte data for processing, converting from string if necessary
func getInputDataForProcessing(input Input, predatorDataType PredatorDataType) ([][][]byte, error) {
	switch predatorDataType {
	case PredatorDataTypeString:
		return convertStringToBytes(input.StringData, input.DataType)
	case PredatorDataTypeBytes:
		return input.Data, nil
	default:
		return nil, fmt.Errorf("input %s has no data", input.Name)
	}
}

func (a *Adapter) initializeBatchRequest(batches []BatchInfo, batchRequests []*triton.ModelInferRequest, predatorRequest *PredatorRequest, inferOutputs []*triton.ModelInferRequest_InferRequestedOutputTensor, parameters map[string]*triton.InferParameter) {
	inferInputs := a.createInferInputTensors(predatorRequest.Inputs, batches[0].EndIndex-batches[0].StartIndex)

	for i := range batchRequests {
		if i == len(batchRequests)-1 {
			inferInputs = a.createInferInputTensors(predatorRequest.Inputs, batches[i].EndIndex-batches[i].StartIndex)
		}
		batchRequests[i] = &triton.ModelInferRequest{
			ModelName:    predatorRequest.ModelName,
			ModelVersion: predatorRequest.ModelVersion,
			Inputs:       inferInputs,
			Outputs:      inferOutputs,
			Parameters:   parameters,
		}
		batchRequests[i].RawInputContents = make([][]byte, len(inferInputs))
	}
}

func (a *Adapter) flatten3DByteSlice(batches []BatchInfo, data [][][]byte, datatype string, batchSize int, batchRequests []*triton.ModelInferRequest, inputIdx int, predatorRequest *PredatorRequest, inferOutputs []*triton.ModelInferRequest_InferRequestedOutputTensor, parameters map[string]*triton.InferParameter) {
	rowCount := len(data)
	if rowCount == 0 || len(data[0]) == 0 {
		return
	}

	numFeatures := len(data[0])

	if inputIdx == 0 {
		a.initializeBatchRequest(batches, batchRequests, predatorRequest, inferOutputs, parameters)
	}

	if datatype == datatypeBytes {
		totalSize := make([]int, len(batchRequests))
		totalByteSize := 0
		for rowIdx := 0; rowIdx < rowCount; rowIdx++ {
			for featureIdx := 0; featureIdx < numFeatures; featureIdx++ {
				featureSize := len(data[rowIdx][featureIdx])
				totalSize[rowIdx/batchSize] += 4 + featureSize
				totalByteSize += 4 + featureSize
			}
		}

		buffer := make([]byte, totalByteSize)
		offset := 0

		for i := range batchRequests {
			batchRequests[i].RawInputContents[inputIdx] = buffer[offset : offset+totalSize[i]]
			offset += totalSize[i]
		}

		lengthBytes := make([]byte, 4)

		count := 0
		for rowIdx := 0; rowIdx < rowCount; rowIdx++ {
			if rowIdx%batchSize == 0 {
				count = 0
			}
			for featureIdx := 0; featureIdx < numFeatures; featureIdx++ {
				stringData := data[rowIdx][featureIdx]
				binary.LittleEndian.PutUint32(lengthBytes, uint32(len(stringData)))
				batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count] = lengthBytes[0]
				batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count+1] = lengthBytes[1]
				batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count+2] = lengthBytes[2]
				batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count+3] = lengthBytes[3]
				count += 4
				for i := range stringData {
					batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count] = stringData[i]
					count++
				}
			}
		}
	} else {
		totalSize := make([]int, len(batchRequests))
		totalByteSize := 0
		for rowIdx := 0; rowIdx < rowCount; rowIdx++ {
			for featureIdx := 0; featureIdx < numFeatures; featureIdx++ {
				featureSize := len(data[rowIdx][featureIdx])
				totalSize[rowIdx/batchSize] += featureSize
				totalByteSize += featureSize
			}
		}

		buffer := make([]byte, totalByteSize)
		offset := 0

		for i := range batchRequests {
			batchRequests[i].RawInputContents[inputIdx] = buffer[offset : offset+totalSize[i]]
			offset += totalSize[i]
		}

		count := 0
		for rowIdx := 0; rowIdx < rowCount; rowIdx++ {
			if rowIdx%batchSize == 0 {
				count = 0
			}
			for featureIdx := 0; featureIdx < numFeatures; featureIdx++ {
				for i := range data[rowIdx][featureIdx] {
					batchRequests[rowIdx/batchSize].RawInputContents[inputIdx][count] = data[rowIdx][featureIdx][i]
					count++
				}
			}
		}
	}
}

// Element size lookup table for better performance
var elementSizeMap = map[string]int{
	"FP32":  4,
	"BF16":  2,
	"FP16":  2,
	"INT64": 8,
	"INT32": 4,
	"INT16": 2,
	"INT8":  1,
	"BOOL":  1,
	"BYTES": -1, // Variable length, needs special handling
}

func getElementSize(datatype string) int {
	if size, ok := elementSizeMap[datatype]; ok {
		return size
	}
	return -1 // default
}

func (a *Adapter) createInferInputTensors(inputs []Input, batchSize int) []*triton.ModelInferRequest_InferInputTensor {
	inferInputs := make([]*triton.ModelInferRequest_InferInputTensor, len(inputs))
	for i, input := range inputs {
		shape := make([]int64, len(input.Dims)+1)
		shape[0] = int64(batchSize)
		for j, dim := range input.Dims {
			shape[j+1] = int64(dim)
		}
		inferInputs[i] = &triton.ModelInferRequest_InferInputTensor{
			Name:     input.Name,
			Datatype: input.DataType,
			Shape:    shape,
		}
	}
	return inferInputs
}

func (a *Adapter) createInferOutputTensors(outputs []Output) []*triton.ModelInferRequest_InferRequestedOutputTensor {
	inferOutputs := make([]*triton.ModelInferRequest_InferRequestedOutputTensor, len(outputs))
	for i, output := range outputs {
		inferOutputs[i] = &triton.ModelInferRequest_InferRequestedOutputTensor{
			Name: output.Name,
		}
	}
	return inferOutputs
}

func (a *Adapter) createSequenceParameters(predatorRequest *PredatorRequest) map[string]*triton.InferParameter {
	parameters := make(map[string]*triton.InferParameter)

	if predatorRequest.SequenceId != nil {
		parameters["sequence_id"] = &triton.InferParameter{
			ParameterChoice: &triton.InferParameter_StringParam{
				StringParam: *predatorRequest.SequenceId,
			},
		}
	}
	if predatorRequest.SequenceStart != nil {
		parameters["sequence_start"] = &triton.InferParameter{
			ParameterChoice: &triton.InferParameter_BoolParam{
				BoolParam: *predatorRequest.SequenceStart,
			},
		}
	}
	if predatorRequest.SequenceEnd != nil {
		parameters["sequence_end"] = &triton.InferParameter{
			ParameterChoice: &triton.InferParameter_BoolParam{
				BoolParam: *predatorRequest.SequenceEnd,
			},
		}
	}

	return parameters
}

func (a *Adapter) MapPredatorRequestToProto(predatorRequest *PredatorRequest, predatorDataType PredatorDataType, batches []BatchInfo) []*triton.ModelInferRequest {
	if len(batches) == 0 {
		return nil
	}

	inferOutputs := a.createInferOutputTensors(predatorRequest.Outputs)
	parameters := a.createSequenceParameters(predatorRequest)

	batchRequests := make([]*triton.ModelInferRequest, len(batches))

	for i, input := range predatorRequest.Inputs {
		inputData, err := getInputDataForProcessing(input, predatorDataType)
		if err != nil {
			log.Error().Err(err).
				Str("input_name", input.Name).
				Msg("Failed to process input data")
			continue
		}

		a.flatten3DByteSlice(batches, inputData, input.DataType, predatorRequest.BatchSize, batchRequests, i, predatorRequest, inferOutputs, parameters)
	}
	a.InferAndSetInputShapes(predatorRequest, batchRequests, batches)
	return batchRequests
}

func (a *Adapter) MapProtoToPredatorResponse(tritonResponse *triton.ModelInferResponse, requestedOutputs []Output, predatorDataType PredatorDataType) *PredatorResponse {
	if utils.IsNilPointer(tritonResponse) {
		log.Warn().Msg("Received nil triton response")
		return nil
	}

	tritonOutputIndex := make(map[string]int)
	for i, output := range tritonResponse.Outputs {
		tritonOutputIndex[output.Name] = i
	}

	// Calculate rowCount once, assuming all outputs have the same batch size
	rowCount := int(tritonResponse.Outputs[0].Shape[0])

	// Pre-calculate total number of outputs for better memory allocation
	totalOutputs := 0
	for _, reqOut := range requestedOutputs {
		if _, ok := tritonOutputIndex[reqOut.Name]; ok {
			totalOutputs += len(reqOut.ModelScores)
		}
	}
	outputs := make([]ResponseOutput, 0, totalOutputs)

	for _, reqOut := range requestedOutputs {
		tritonIdx, ok := tritonOutputIndex[reqOut.Name]
		if !ok {
			continue
		}
		tritonOut := tritonResponse.Outputs[tritonIdx]
		tritonData := tritonResponse.RawOutputContents[tritonIdx]

		datatype := tritonOut.Datatype
		numScores := len(reqOut.ModelScores)
		elementSize := getElementSize(datatype)

		// For BYTES, parse the length-prefixed format
		if datatype == "BYTES" {
			// Parse all strings sequentially first
			totalStrings := rowCount * numScores
			allStrings := make([][]byte, totalStrings) // Initialize with nil values
			offset := 0
			parsedCount := 0

			// Parse as many strings as available in the data
			for parsedCount < totalStrings && offset+4 <= len(tritonData) {
				// Read 4-byte length prefix
				strLen := int(binary.LittleEndian.Uint32(tritonData[offset : offset+4]))

				// Extract length prefix + string content
				totalLen := 4 + strLen
				if offset+totalLen > len(tritonData) {
					break
				}
				allStrings[parsedCount] = tritonData[offset+4 : offset+totalLen]
				offset += totalLen
				parsedCount++
			}

			// Group by score
			for scoreIdx, scoreName := range reqOut.ModelScores {
				data := make([][]byte, rowCount)
				for b := 0; b < rowCount; b++ {
					stringIdx := b*numScores + scoreIdx
					if stringIdx < len(allStrings) && allStrings[stringIdx] != nil {
						data[b] = allStrings[stringIdx]
					}
					// data[b] remains nil for missing batches
				}

				// Construct shape: batch_size + dimensions for this specific score
				var shape []int64
				shape = append(shape, int64(rowCount))
				if scoreIdx < len(reqOut.Dims) {
					for _, dim := range reqOut.Dims[scoreIdx] {
						shape = append(shape, int64(dim))
					}
				}

				// Conditionally populate StringData or Data based on original input type
				var stringData [][]string
				if predatorDataType == PredatorDataTypeString {
					// Only convert to strings if original input was string data
					convertedStringData, err := convertBytesToStringWithNils(data, datatype)
					if err != nil {
						log.Error().Err(err).
							Str("output_name", scoreName).
							Str("datatype", datatype).
							Msg("Failed to convert bytes to string for output")
					} else {
						stringData = convertedStringData
					}
				}

				outputs = append(outputs, ResponseOutput{
					Name:       scoreName,
					DataType:   datatype,
					Shape:      shape,
					Data:       data,       // Always include byte data (needed for processing)
					StringData: stringData, // Only populated if original input was string
				})
			}
			continue
		}

		// Calculate individual score sizes based on their specific dimensions
		scoreSizes := make([]int, numScores)
		totalSizePerBatch := 0

		for scoreIdx := 0; scoreIdx < numScores; scoreIdx++ {
			elements := 1
			if scoreIdx < len(reqOut.Dims) && len(reqOut.Dims[scoreIdx]) > 0 {
				for _, dim := range reqOut.Dims[scoreIdx] {
					elements *= dim
				}
			}
			scoreSize := elementSize * elements
			scoreSizes[scoreIdx] = scoreSize
			totalSizePerBatch += scoreSize
		}

		// Calculate expected total size and actual available size
		expectedTotalSize := rowCount * totalSizePerBatch
		availableSize := len(tritonData)

		// Calculate how many complete batches we have
		completeBatches := availableSize / totalSizePerBatch
		if completeBatches > rowCount {
			completeBatches = rowCount
		}

		// Log warning if some data is missing
		if availableSize < expectedTotalSize {
			missingBatches := rowCount - completeBatches
			log.Warn().
				Int("expected_size", expectedTotalSize).
				Int("available_size", availableSize).
				Int("expected_batches", rowCount).
				Int("complete_batches", completeBatches).
				Int("missing_batches", missingBatches).
				Msg("Some batch data is missing, filling with nil values")
		}

		// Pre-calculate cumulative offsets to avoid O(nÂ²) calculation
		cumulativeOffsets := make([]int, numScores)
		if numScores > 0 {
			cumulativeOffsets[0] = 0
			for scoreIdx := 1; scoreIdx < numScores; scoreIdx++ {
				cumulativeOffsets[scoreIdx] = cumulativeOffsets[scoreIdx-1] + scoreSizes[scoreIdx-1]
			}
		}

		for scoreIdx, scoreName := range reqOut.ModelScores {
			scoreSize := scoreSizes[scoreIdx]
			data := make([][]byte, rowCount)

			scoreOffsetInBatch := cumulativeOffsets[scoreIdx]
			for b := 0; b < rowCount; b++ {
				// Calculate offset: batch offset + score offset within batch
				offset := b*totalSizePerBatch + scoreOffsetInBatch
				endOffset := offset + scoreSize

				// Only extract data if we have enough data for this batch
				if endOffset <= availableSize {
					data[b] = tritonData[offset:endOffset]
				}
				// data[b] remains nil for missing batches
			}

			// Construct shape: batch_size + dimensions for this specific score
			var shape []int64
			shape = append(shape, int64(rowCount))
			if scoreIdx < len(reqOut.Dims) {
				for _, dim := range reqOut.Dims[scoreIdx] {
					shape = append(shape, int64(dim))
				}
			}

			// Conditionally populate StringData or Data based on original input type
			var stringData [][]string
			if predatorDataType == PredatorDataTypeString {
				// Only convert to strings if original input was string data
				convertedStringData, err := convertBytesToStringWithNils(data, datatype)
				if err != nil {
					log.Error().Err(err).
						Str("output_name", scoreName).
						Str("datatype", datatype).
						Msg("Failed to convert bytes to string for output")
				} else {
					stringData = convertedStringData
				}
			}

			outputs = append(outputs, ResponseOutput{
				Name:       scoreName,
				DataType:   datatype,
				Shape:      shape,
				Data:       data,       // Always include byte data (needed for processing)
				StringData: stringData, // Only populated if original input was string
			})
		}
	}

	return &PredatorResponse{
		ModelName:    tritonResponse.ModelName,
		ModelVersion: tritonResponse.ModelVersion,
		Outputs:      outputs,
	}
}

// convertStringToBytes converts string data to bytes based on the specified data type
func convertStringToBytes(stringData [][][]string, dataType string) ([][][]byte, error) {
	byteData := make([][][]byte, len(stringData))

	for batchIdx, batch := range stringData {
		byteData[batchIdx] = make([][]byte, len(batch))
		for featureIdx, feature := range batch {
			switch dataType {
			case "FP32":
				bytes := make([]byte, len(feature)*4)
				for i, str := range feature {
					val, err := strconv.ParseFloat(str, 32)
					if err != nil {
						return nil, fmt.Errorf("failed to parse float32 from string %s: %v", str, err)
					}
					binary.LittleEndian.PutUint32(bytes[i*4:(i+1)*4], math.Float32bits(float32(val)))
				}
				byteData[batchIdx][featureIdx] = bytes
			case "INT32":
				bytes := make([]byte, len(feature)*4)
				for i, str := range feature {
					val, err := strconv.ParseInt(str, 10, 32)
					if err != nil {
						return nil, fmt.Errorf("failed to parse int32 from string %s: %v", str, err)
					}
					binary.LittleEndian.PutUint32(bytes[i*4:(i+1)*4], uint32(val))
				}
				byteData[batchIdx][featureIdx] = bytes
			case "INT64":
				bytes := make([]byte, len(feature)*8)
				for i, str := range feature {
					val, err := strconv.ParseInt(str, 10, 64)
					if err != nil {
						return nil, fmt.Errorf("failed to parse int64 from string %s: %v", str, err)
					}
					binary.LittleEndian.PutUint64(bytes[i*8:(i+1)*8], uint64(val))
				}
				byteData[batchIdx][featureIdx] = bytes
			case "BOOL":
				bytes := make([]byte, len(feature))
				for i, str := range feature {
					val, err := strconv.ParseBool(str)
					if err != nil {
						return nil, fmt.Errorf("failed to parse bool from string %s: %v", str, err)
					}
					if val {
						bytes[i] = 1
					} else {
						bytes[i] = 0
					}
				}
				byteData[batchIdx][featureIdx] = bytes
			case "BYTES":
				// For BYTES type, just convert string to bytes
				byteData[batchIdx][featureIdx] = []byte(feature[0])
			default:
				return nil, fmt.Errorf("unsupported data type for string conversion: %s", dataType)
			}
		}
	}

	return byteData, nil
}

// convertBytesToString converts byte data to strings based on the specified data type
func convertBytesToString(byteData [][]byte, dataType string) ([][]string, error) {
	stringData := make([][]string, len(byteData))

	for batchIdx, batch := range byteData {
		switch dataType {
		case "FP32":
			strings := make([]string, len(batch)/4)
			for i := 0; i < len(strings); i++ {
				bits := binary.LittleEndian.Uint32(batch[i*4 : (i+1)*4])
				val := math.Float32frombits(bits)
				strings[i] = strconv.FormatFloat(float64(val), 'f', -1, 32)
			}
			stringData[batchIdx] = strings
		case "INT32":
			strings := make([]string, len(batch)/4)
			for i := 0; i < len(strings); i++ {
				val := int32(binary.LittleEndian.Uint32(batch[i*4 : (i+1)*4]))
				strings[i] = strconv.FormatInt(int64(val), 10)
			}
			stringData[batchIdx] = strings
		case "INT64":
			strings := make([]string, len(batch)/8)
			for i := 0; i < len(strings); i++ {
				val := int64(binary.LittleEndian.Uint64(batch[i*8 : (i+1)*8]))
				strings[i] = strconv.FormatInt(val, 10)
			}
			stringData[batchIdx] = strings
		case "BOOL":
			strings := make([]string, len(batch))
			for i, b := range batch {
				strings[i] = strconv.FormatBool(b != 0)
			}
			stringData[batchIdx] = strings
		case "BYTES":
			// For BYTES type, just convert bytes to string
			stringData[batchIdx] = []string{string(batch)}
		default:
			return nil, fmt.Errorf("unsupported data type for byte conversion: %s", dataType)
		}
	}

	return stringData, nil
}

// convertBytesToStringWithNils converts byte data to strings, handling nil byte slices
func convertBytesToStringWithNils(byteData [][]byte, dataType string) ([][]string, error) {
	stringData := make([][]string, len(byteData))

	for batchIdx, batch := range byteData {
		if batch == nil {
			// For nil batches, create nil string slice
			stringData[batchIdx] = nil
			continue
		}

		switch dataType {
		case "FP32":
			strings := make([]string, len(batch)/4)
			for i := 0; i < len(strings); i++ {
				bits := binary.LittleEndian.Uint32(batch[i*4 : (i+1)*4])
				val := math.Float32frombits(bits)
				strings[i] = strconv.FormatFloat(float64(val), 'f', -1, 32)
			}
			stringData[batchIdx] = strings
		case "INT32":
			strings := make([]string, len(batch)/4)
			for i := 0; i < len(strings); i++ {
				val := int32(binary.LittleEndian.Uint32(batch[i*4 : (i+1)*4]))
				strings[i] = strconv.FormatInt(int64(val), 10)
			}
			stringData[batchIdx] = strings
		case "INT64":
			strings := make([]string, len(batch)/8)
			for i := 0; i < len(strings); i++ {
				val := int64(binary.LittleEndian.Uint64(batch[i*8 : (i+1)*8]))
				strings[i] = strconv.FormatInt(val, 10)
			}
			stringData[batchIdx] = strings
		case "BOOL":
			strings := make([]string, len(batch))
			for i, b := range batch {
				strings[i] = strconv.FormatBool(b != 0)
			}
			stringData[batchIdx] = strings
		case "BYTES":
			// For BYTES type, just convert bytes to string
			stringData[batchIdx] = []string{string(batch)}
		default:
			return nil, fmt.Errorf("unsupported data type for byte conversion: %s", dataType)
		}
	}

	return stringData, nil
}

func (a *Adapter) InferAndSetInputShapes(predatorRequest *PredatorRequest, batchReqs []*triton.ModelInferRequest, batches []BatchInfo) {
	for batchIdx := range batches {
		for inputIdx := range predatorRequest.Inputs {
			totalByteSize := len(batchReqs[batchIdx].RawInputContents[inputIdx])
			inputDataType := GetFeatureStoreTypeFromPredator(predatorRequest.Inputs[inputIdx].DataType)
			inputByteSize := 0
			if inputDataType == datatypeBytes {
				inputByteSize = 4
				featureLen := binary.LittleEndian.Uint32(batchReqs[batchIdx].RawInputContents[inputIdx][0:4])
				inputByteSize += int(featureLen)
			} else {
				if !strings.Contains(inputDataType, "DataType") {
					inputDataType = "DataType" + inputDataType
				}
				parsedInputDataType, err := types.ParseDataType(inputDataType)
				if err != nil {
					log.Error().Err(err).
						Str("input_name", predatorRequest.Inputs[inputIdx].Name).
						Msg("Failed to parse input data type")
					continue
				}
				inputByteSize = parsedInputDataType.Size()
			}
			if len(batchReqs[batchIdx].Inputs[inputIdx].Shape) > 2 {
				unknownIdx := -1
				knownSizes := 1
				for i, dim := range batchReqs[batchIdx].Inputs[inputIdx].Shape {
					if dim == -1 {
						unknownIdx = i
					} else {
						knownSizes *= int(dim)
					}
				}
				if unknownIdx != -1 {
					if inputByteSize == 0 {
						log.Error().
							Str("input_name", predatorRequest.Inputs[inputIdx].Name).
							Msg("Input data type is not supported")
						continue
					}
					batchReqs[batchIdx].Inputs[inputIdx].Shape[unknownIdx] = int64(totalByteSize / (knownSizes * inputByteSize))
				}
			} else {
				if batchReqs[batchIdx].Inputs[inputIdx].Shape[1] == -1 {
					if inputByteSize == 0 {
						log.Error().
							Str("input_name", predatorRequest.Inputs[inputIdx].Name).
							Msg("Input data type is not supported")
						continue
					}
					batchReqs[batchIdx].Inputs[inputIdx].Shape[1] = int64(totalByteSize / (int(batchReqs[batchIdx].Inputs[inputIdx].Shape[0]) * inputByteSize))
				}
			}
		}
	}
}

func GetFeatureStoreTypeFromPredator(predatorDataType string) string {
	switch predatorDataType {
	case "INT8":
		return "Int8"
	case "INT16":
		return "Int16"
	case "INT32":
		return "Int32"
	case "INT64":
		return "Int64"
	case "UINT8":
		return "Uint8"
	case "UINT16":
		return "Uint16"
	case "UINT32":
		return "Uint32"
	case "UINT64":
		return "Uint64"
	case "STRING":
		return "String"
	case "BOOL":
		return "Bool"
	default:
		return predatorDataType
	}
}
